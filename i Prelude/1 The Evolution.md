# 第一部分 演化

本部分给出Swarm的设计和演化的背景信息、以及目前的愿景。第1.1节回顾万维网的历史，重点关注它是如何发展成为今天的样子的。第1.2节介绍了Swarm的概念，并解释了数据主权、集体信息和公平数据经济的重要性。这一节讨论了一个自治社会所需要的基础设施，并且这种基础设施能够共同托管、移动和处理数据。最后，第1.3节概述了Swarm愿景背后的价值观，阐明了技术需求，并列出了指导我们创造Swarm的设计原则。



## 1 历史观点

更一般的说，是互联网；更具体的说，是万维网（WWW）——极大地降低了信息传播的成本，把出版商的力量放在每一个用户的指尖。但信息传播的成本仍不为零，并且这些成本的分布严重影响谁来发布内容，谁来使用内容。

为了理解Swarm试图解决的问题，让我们对万维网发展的历史快速地回顾一下。

#### 1.1 Web 1.0

在Web 1.0时代，为了让全世界都能访问到你生产的内容，你通常会启动一个Web服务器，或者把内容上传到免费或廉价的Web托管空间中，然后在一组HTML页面中导航内容。如果你的内容不是很流行，你仍然需要维护服务器或者支付托管费用来保持它的可访问性。但是当出于某种原因，托管内容突然变得流行（例如，当你被“slashdot”）时，真正的灾难发生了。此时，在内容对大多数用户基本上不可用之前（服务器崩溃或主机提供商限制你的带宽），你的流量账单飙升。如果你想要保持内容流行，你必须投资与高速网络连接的高可用性集群，你的成本和你的知名度一起增长，没有任何好的方式来覆盖这些成本。很少有实用的方法可以让（更不用说要求）你的用户和你直接分担随之而来的经济负担。

当时的普遍看法是，在网络革命的早期，互联网服务提供商（ISP）可以拯救这些内容提供者。互联网服务提供商之间对对等节点的部署讨价还价：涉及到内容提供者和消费者的位置，以及ISP如何从其他ISP网络中赚钱。事实上，当TCP连接请求的发起者（也就是SYN包）之间存在严重的不平衡时，发起者ISP通常会向接收方ISP支付费用，这使得后者在某种程度上有动力支持那些托管流行内容的Web服务器。然而，在实践中，这种激励结构通常导致在服务器中放置一个免费的pr0n或warez服务器，以降低SYN包计数器的规模。迎合小规模受众的博客没有办法竞争，通常被冷落。然而，请注意，在那个时候，生产者和出版者仍然可以拥有自己的内容。

#### 1.2 Web 2.0

万维网在向Web 2.0转变的过程中改变了很多。这种改变是从个人主页（运行在自己的服务器上，使用提姆·伯纳斯李的优雅，简单和易用的超文本标记语言）向服务器脚本（使用cgi-gateways超文本标记语言,perl和php）的迁移。脚本语言必然导致不同美丽想法的产生，任何人都可以使用简单的工具编写和运行他们自己的网站。这使得网络走上了一条极其困难且越来越复杂的脚本语言和数据库堆栈的道路。突然间，万维网不再是一个初学者友好的地方。同时，新技术的出现使得Web应用程序能够创建。这些应用程序可以提供简单的用户界面，使非技术内容提供者只需要上传数据到服务器上即可。这导致内容提供和内容交付的分离。就这样，Web 2.0诞生了。

像MySpace和Geocities这样的网站抓住了网络最初的创造者精神，现在已经主宰了潮流。这些网站为用户提供了一块可以称之为“完整”的互联网，有尽可能多的滚动文本字幕，闪烁着粉色闪光的Comic Sans横幅，以及脚本新手可以梦想的所有巧妙的XSS攻击。这是一个网络中的网络，一个可访问和开放的环境，让用户开始发布自己的内容，不需要学习HTML，也没有规则。平台大量涌现，突然间每个人都有了一席之地，有了phpBB论坛，所有人都有了兴趣。互联网变得生机勃勃，互联网繁荣给硅谷带来了大量财富。

当然，这个年轻的，天真的，彩虹般的游乐场不会持续太久。以不可靠著称的MySpace成了其允许脚本的开放政策的受害者。用户的页面变得不可靠，平台变得不可用。当Facebook带来了一个外观整洁、运行良好的界面时，MySpace的时代就结束了，人们大量迁移到Facebook上。流行的互联网有了一种更加自负的意味，我们鱼贯进入了Facebook赤裸裸的白色公司办公室。但麻烦接踵而至。在“免费”提供这项服务的同时，扎克伯格和其他人也有自己的计划。作为对托管我们数据的回报，我们（愚蠢的fucks[Carlson, 2010]）将不得不信任他。显然，我们就是这么做的。当时，Facebook除了吸引更多的风险投资，积累大量的用户基础之外，表面上没有商业模式，我们可以以后再来处理这个问题。但从一开始，广泛且难以阅读的T&C（用户须知）便将所有内容的使用权利赋予了平台。在Web 1.0中，保存网站的备份并迁移到一个新的主机上很容易，或者干脆托管在自己家里。现在那些颇有争议争议的观点有了一个新的动词来描述：“去平台化”。

在基础设施层面，这种中心化开始体现在无法想象的巨大数据中心上。杰夫·贝索斯（Jeff Bezos）通过帮助那些无法应对技术和财务障碍且无法实施日益复杂和昂贵的基础设施的人，大力发展他的图书销售业务并成为地球上最富有的人。无论如何，这个新的”星座“有能力应对那些不规则流量峰值（过去破坏了大量成功的内容提供者）。其他公司紧随其后，很快，大多数网络开始由少数几家大公司托管。企业收购和源源不断的风投资金使得权力越来越集中。一个被遗忘的开源程序员联盟，他们创建了免费的Apache web服务器，他们创建了谷歌，他们提供了范式转移的方式来组织和访问指数级增长的数据，帮助微软将网络变成一个地狱般的、专有的存在，并被囚禁在IE6里。当然，谷歌最终接受了“父母的监督”，放弃了“不做坏事”的承诺，屈服于自身形式的自大狂，开始吞噬竞争对手。渐渐地，电子邮件变成了Gmail，在线广告变成了AdSense，谷歌逐渐渗透到网络日常生活的方方面面。

表面上，一切都很美好。技术乌托邦以一种无人能想象的方式将世界超连接起来。网络不再只是学术界和超级1337的专利，它让所有人都能获得人类知识的总和。现在智能手机无处不在，可以在任何地方访问网络。维基百科赋予每个人超人的知识，谷歌让我们可以在一瞬间找到并访问它，Facebook让我们可以免费与我们认识的每个人交流。然而，在这一切的背后，有一个问题隐藏在闪闪发光的外表之下。谷歌自己知道他们正在做什么。亚马逊(Amazon)、Facebook和微软(Microsoft)也是如此。从1984年开始，一些朋克也这样做了。

一旦这些庞大的平台拥有了所有的用户，是时候给投资者开出一张支票了。是时候制定一种商业模式了。为了向股东提供价值，内容提供平台发现广告收入是灵丹妙药。其他方法，都不可行。谷歌可能真的试过了，但想不出其他选择。现在网络开始变得复杂，让人无法专心。广告无处不在，粉色闪烁的横幅广告又回来了，这一次是把你的注意力从你想要的内容上吸引过来，把你作为获取下一个用户的机会。

似乎这还不够，更多的恐怖即将来临。当数据的扩散变得笨拙，算法被作为一种“帮助”手段更好地为我们提供我们想要的内容时，网络失去了最后一丝纯真。现在这些平台拥有了我们所有的数据，它们能够分析这些数据来得出我们想要看到的东西，似乎比我们以前更了解我们自己。每个人都会被投喂他们最喜欢的零食，以及他们最可能购买的产品。这些秘密算法和所有包含的数据集有一个陷阱：它们被卖给出价最高的人。财力雄厚的政治组织能够以前所未有的准确性和效力瞄准摇摆选民。网络空间突然间变成了一个非常真实的东西，就像共识和常态突然成为了过去。新闻不仅变成了假新闻，还变成了针对个人的操纵，常常是为了促使你在没有意识到的情况下做出违背自己最大利益的行为。

为了节省内容的托管成本，每个人都变成了一个易于控制的傀儡。事实已经如此。

与此同时，更可怕的真相正在等待着我们。事实证明，最初推动建立可信互联网的平等主义理想是最幼稚的。实际上，国防部把互联网带给你，现在又想要回来。爱德华·斯诺登（Edward Snowden）带着一大堆文件离开了美国国家安全局（NSA）。这没人能想象的到，除非，你把《谍影重重》当做纪录片来看。结果，协议被打破了，所有的逮捕金丝雀早已死亡——世界各国政府一直在对整个世界人口进行监视——不断地对个人在线活动数据进行存储、处理、编目、索引，并提供总量分析。无论是谁或什么样的环境，只要轻触一个XKeyStore按钮，就可以获得所有信息，一个能看到一切、一眼不眨的Optical Nerve可以“收集所有信息”并“了解所有信息”。老大哥看起来像索伦。对隐私的严重侵犯——在此之前，世界各地的各种权力痴迷狂或自大狂的机构和个人还做出了许多类似的努力，以追踪和屏蔽信息（被镇压的人民，政治对手或记者，被政权攻击的目标），为Tor（洋葱）项目提供动力。美国军方、麻省理工学院和电子前沿基金会之间的这种不同寻常的合作不仅提供了一种混淆监控请求的方式，而且还以一种受保护的匿名方式获取内容。此时的互联网在某些领域非常成功，家喻户晓，但由于其固有的低效率导致了相对较高的延迟，在其他领域并没有多大用处。

```
译者注：一些公司使用逮捕金丝雀来警告客户他们的隐私会因为美国政府的传票而受到威胁。
译者注：索伦是托尔金的小说《指环王》中的主角和主要反派。在《指环王》中，索伦统治着魔多王国，并有统治整个中土世界的野心。
```

到斯诺登泄密事件发生的时候，网络已经无处不在，几乎与人类生活的方方面面完全融为一体，但其中绝大部分是由企业运营的。虽然可靠性问题已成为过去，但也要付出代价。内容敏感、目标明确的广告模式现在把他们浮士德式交易扩展到内容生产者，带着知道内容生产者别无选择的笑容。“我们将给您提供可伸缩的托管服务器，这些服务器可以处理您的用户带来的任何流量压力”，这些大企业说的很好听，“但作为回报，您必须让我们控制您的内容：我们将跟踪您的每一位用户，并尽可能收集（并拥有，‘吹口哨’）他们的个人数据。当然，我们将决定谁能看到它，谁不能看到它，这同样是我们的权利。我们会主动审查它，并在保护我们业务的谨慎前提下自然地与当局政府分享您的数据。” 多么完美的浮士德交易！

```
浮士德式交易:一个人用最高的道德或精神层面重要性的东西，如个人价值或灵魂，来换取一些世俗或物质利益，如知识、权力或财富的契约。
```

暂且不谈我们今天所见证的Web 2.0数据和新闻宣传所带来的FUD结果，互联网的体系结构还存在一些技术问题。目前企业的方法产生了一个中心原则，因此所有请求现在必须通过某个主干网络路由到一个单一的数据中心，然后传递、处理，最后返回。即使只是给隔壁房间的人发个信息，也要经历这样的过程。这是一种客户端-服务器架构。不是事后诸葛亮，这种架构充其量也只有很脆弱的安全性，而且经常遭到攻击，因此信息泄露成为一种新常态，导致未加密的个人数据甚至明文密码散布在整个网络上。最后一根钉子钉在了棺材上，这导致了杂乱无章的不连贯标准和界面。如今，复杂程度不断增长的意大利面条式代码将Web细分为各种各样的微服务。即使是那些财大手快的公司也发现越来越难以应付开发成本，而且现在羽翼未丰的初创公司淹没在快速变化的feature海洋和螺旋上升的技术债务海洋中。一个现代Web应用程序堆栈在任何情况下都是一个拼凑在一起的Heath-Robinson机器，它包含了如此多的活动部件，以至于即使是一个超国家的公司（说实话，除了谷歌和亚马逊），也几乎不可能维护和开发这些实现，而不产生大量的错误和常规的安全缺陷。无论如何，是时候重启了。最后，是数据描述了我们的生活。大企业虽然已经试过，但它们没有能力把我们困在这个烂摊子里。

```
译者注：恐惧（Fear）、不确定（Uncertainty）和怀疑（Doubt）（通常缩写为FUD）是一种用于销售、营销、公共关系、政治、民调和邪教的宣传策略。FUD一般是一种通过传播负面、可疑、虚假的信息来影响看法的策略，是引发恐惧的一种手段。
```

```
译者注：Heath-Robinson，希斯·罗宾逊，英国艺术家、讽刺作家和插画家。在他的许多作品中，他讽刺了人类对机器的痴迷，绘制了复杂的绞车和滑轮系统，这些系统由带有踏板、磁铁、管道和杠杆的蒸汽锅炉提供动力，这些蒸汽锅炉摇摇欲坠地组装成巨大的结构，所有这些都被描绘成具有讽刺意味的宏伟工程且执行平凡任务。
```

#### 1.3 对等网络

当Web 2.0的中心化接管世界时，点对点（P2P）革命也在加速发展，只是在悄悄地并行发展。实际上，P2P流量很快就占据了流经互联网管道的大部分数据包，迅速超过了上述SYN诱饵服务器。如果有什么区别的话，P2P毫无疑问地证明了终端用户通过共同努力利用他们迄今尚未充分利用的上行带宽，可以为它们的内容提供同样的可用性和吞吐量。而在以前这些只有大公司的数据中心才能实现，因为这些数据中心处于在互联网骨干网最肥厚的管道上。更重要的是，P2P可以以很低的成本实现。重要的是，用户对自己的数据保留了更多的控制权和自由。最终，这种P2P数据分发模式被证明是非常有弹性的，即使是一些强大且资金充足的实体采取绝望的关闭手段。

然而，即使是当时最先进的P2P文件共享模式，无法追踪的BitTorrent [Pouwelse等人，2005]，也仅仅实现了文件级共享。它无法提供人们所期望的Web 2.0上的那种交互式、响应式体验。除此之外，随着BT越来越流行，BT不再秉持经济学和博弈论的构想。在整个世界注意到革命到来之前，也就是说，在任何人了解区块链以及加密货币和激励的力量之前，BT的名字迅速没落。



#### 1.4 BitTorrent经济学及其限制

BT的天才在于其创新的资源优化（科恩,2003）：如果很多用户想从你这里下载相同的内容，第一个阶段，你给这些用户分发的不同内容；在第二个阶段，让他们以”tit-for-tat“ （针锋相对）的方式交换彼此之间的内容，直到每个人都拥有所有的内容。这样一来，无论有多少用户想同时下载内容，托管内容的用户（BitTorrent中的播种者）的上行带宽占用基本上都是相同的。这就解决了超文本传输协议（HTTP）这种古老的、集中的、主从式的设计中最棘手、最根深蒂固的问题。而HTTP协议是万维网的基础。

对作弊（用垃圾数据喂养对等节点）的抑制使用了分层、分片散列，因此当一个数据包被下载时，该数据包用一个散列值表示，该数据包的任何部分，都可以以加密方式证明是该数据包的特定部分，而不需要知道其他部分的任何信息。而且，这个过程用到的计算开销非常小。

但是这个漂亮而简单的方法有五个重要的缺点，[Locher et al.， 2006, Piatek et al.， 2007]，所有缺点都是相关的。

* 缺乏经济激励机制——没有内置激励机制为下载内容提供种子。特别是，不能将内容播种所需要的上行带宽与内容下载所需要的下行带宽进行交换。实际上，由提供给用户的内容播种所使用的上行带宽并没有得到奖励。因为保留尽可能多的上行带宽可以改善一些在线游戏的体验，所以关掉种子是一个理性的选择。加上一些懒惰，种子就永远消失了。
* 初始延迟——通常情况下，下载启动缓慢，并伴有一些延迟。那些提前下载内容的客户可以提供给新加入节点的内容比他们可以得到的回报要多得多。也就是说，新加入节点还没有任何可下载的内容。这样做的结果是，BitTorrent的下载从涓涓细流开始，然后变成比特的全面洪流。这一缺陷严重限制了BitTorrent在交互式应用程序中的使用。交互式应用程序往往需要快速响应和高带宽，这是许多游戏所需要的特性。
* 缺乏细粒度的内容寻址——在BitTorrent中，小数据块只能作为它们所属的大文件的一部分来共享。这些小数据块可以被指定为目标对象以优化访问，从而将文件的其余部分排除在外。但是下载节点只能通过查询分布式哈希表（DHT）来找到所需的文件。在数据块级别上查找对等节点是不可能的，因为可用内容的通告只发生在文件级别上。这将导致下载效率非常低下，因为相同的数据块经常会完全一样地出现在多个文件中。因此，虽然从理论上讲，所有拥有数据块的对等节点都可以提供数据块，但是无法定位到这些对等节点，因为只有数据块所对应的文件有名称（或者更确切地说，是一个通告的散列值）并可以被检索。
* 没有保持共享的动机——一旦节点实现了它们的目标，即从它们的同伴那里检索所有想要的文件，它们的共享努力（存储和带宽）就无法得到奖励。
* 没有隐私或模糊性——节点宣传他们存储内容的种子。攻击者如果希望看到一个内容被删除，他们很容易发现对等节点的IP地址，然后发起DDOS攻击。或者，公司和国家要求ISP提供连接的物理位置。这导致了一个VPN供应商的灰色市场：帮助用户隐藏自己的位置。尽管这些服务提供了隐私保证，但通常无法验证这些服务，因为这些系统通常是闭源的。

可以说，虽然BitTorrent非常流行，非常有用，但它也是原始的，是天才的第一步。这是在没有适当的计算和索引的情况下，仅仅通过共享我们的上行带宽、硬盘空间和少量的计算能力，我们所能迈出的最大一步。然而，非常惊喜！——如果我们再添加一些新兴技术，当然，最重要的是区块链，我们就会得到一个真正配得上Web 3.0这个名字的东西：一个分散的、抗审查的共享设备，同时也可以集体创建内容，同时保持对内容的完全控制。更重要的是，这一成本几乎完全通过使用和共享个人已经拥有的超级计算机（和过去的个人电脑相比:-)）提供的资源来支付。

#### 1.5 走向Web3.0

《纽约时报》
2009年1月03
财政大臣
将对银行实施
第二轮救助

在2009年1月3日星期六6:15（或之后），这个世界永远地改变了。一个神秘的密码朋克创造了一条将会包围整个世界的区块链的第一个区块，精灵就从瓶子里释放出来了。这第一步将引发一系列反应，将导致前所未有的巨额资金从法定和实物的传统存储手段流入一个全新的价值存储和价值传输工具：加密货币。“中本聪”（Satoshi Nakamato）成功地做了一件前无古人的事情，事实上，他小规模地消除了银行的中介作用，实现去中心化的免信任价值转。从那一刻起，我们实际上又回到了金本位：每个人现在都可以拥有央行的货币。没人能从你口袋里把钱翻出来。更重要的是，现在每个人都可以自己印钱，并有自己的中央银行和电子传输系统。我们仍不清楚这将在多大程度上改变我们的经济。

比特币是一个巨大的第一步，也是一个里程碑式的转折点。现在我们已经将身份验证和价值转移融入了系统的核心。但尽管比特币在概念上很出色，但在实用方面也有一些不太重要的小问题。它可以传输数字价值，人们甚至可以给硬币“上色”，或者发送像上面那个标记第一个区块的决定性日期的短消息。但也就只能做成这样。至于规模……每个交易必须存储在每个节点上。没有内置的分片机制。更糟糕的是，数字货币的保护使得每一个节点都必须在任何时候处理与其他节点完全相同的数据。这与并行计算集群的理念相反，而且要慢几百万倍。

当Vitalik构思以太坊时，他接受了其中的一些限制，但系统的实用性有了巨大的飞跃。他通过增加以太坊虚拟机（EVM）来实现图灵完备计算的设施，这使得大量的应用程序能够在这种免信任的装置中运行。这一概念是一次令人眼花缭乱的范式转移，也是比特币的持续发展。比特币本身是基于一个微型虚拟机，每一笔交易实际上都是一个小程序——很多人都不知道这一点。但以太坊持续发展，再次改变了一切。各种可能性数不胜数，前景诱人，Web 3.0诞生了。

然而，当完全超越Web 2.0世界时，仍然有一个问题需要克服：在区块链上存储数据的成本高昂，令人望而却步。比特币和以太坊都采用了BitTorrent的存储布局，并采用类似的运行方式，以交易能力补充BitTorrent的架构，但将非系统性数据的存储留到以后考虑。实际上，比特币在区块分发之外增加了第二条安全度低得多的线路：作为二等公民，候选交易在没有任何宣传的情况下进行，实际上是没有协议的[TODO：这里解释的更清楚一些]。以太坊走得更远，将数据头从数据块中分离出来，创建了第三层，根据需要临时传递真正的数据块。因为这两类数据对系统的操作都是必不可少的，所以可以称之为关键设计缺陷。比特币的设计者可能没有预见到挖矿已经成为高度专业化的精英专属领域。任何交易者都可以打包他们自己的交易。以太坊面临着数据可用性的更大挑战，大概是因为很明显，这个问题可以稍后单独解决，所以暂时忽略它。

在其他新闻中，BitTorrent数据传播的直接方法已经被ZeroNet成功地用于Web内容分发[ZeroNet社区，2019]。然而，由于前面提到的BT问题，ZeroNet无法支持Web服务用户所期望的响应性。

为了尝试解决响应性问题，分布式Web应用程序（或dapps）， 星际文件系统（IPFS） [IPFS, 2014]介绍了他们自己基于BT的改进。IPFS的一个突出特征是高度兼容Web，并且使用基于URL的检索方案。此外，可用数据的目录、索引（就像以DHT形式组织的BitTorrent）得到了极大的改进，使得搜索任何文件的一小部分（称为数据块）成为可能。

有许多其他方面的努力来解决这些问题，并提供一个有价值的用于Web 3.0的服务器和服务的集合。这是Web 2.0开发人员所期望的，因为这种方案提供一条途径，从现有的支持数据收割的集中式架构中解放出来。这些都不是无足轻重的角色，即使是今天最简单的Web应用程序也包含了不可思议的大量概念和范式，这些概念和范式必须被重新映射到Web 3.0的免信任设置中。在许多方面，这个问题被证明可能比在区块链中实现免信任的计算更加微妙。Swarm用一系列精心设计的数据结构来回应这一问题，这些数据结构使应用程序开发人员能够在Web 3.0的新环境中重新创建我们在Web 2.0中已经习惯的概念。Swarm重新构想了当前的网络产品，重新实现了坚实的加密经济基础。

想象一个变化的范围，从左边开始：大文件，低检索频率和更加单一的API；从右边开始：小数据包，高频率的检索，和一个精细的API。在这个范围内，Posix文件系统、S3、Storj和BitTorrent等文件存储和检索系统位于左侧。键值存储（如LevelDB）和数据库（如MongoDB或Postgres）位于右侧。为了构建一个有用的应用程序，需要不同的模式，而且必须有能力在必要的时候合并数据，并确保只有授权方可以访问受保护的数据。在中间派模型中，最初很容易处理这些问题，但随着数据规模的增长，问题会越来越难处理，但每个范围都有来自某个专门软件的解决方案。然而，在去中心化模型中，所有的赌注都失败了。授权必须用密码学来处理，并且数据的组合受此限制。因此，在当今新生的、不断发展的Web 3.0堆栈中，许多解决方案只处理这一需求范围的一部分。在本书中，读者将了解Swarm如何服务于整个范围，以及如何为Web 3.0开发人员的新装备提供高级工具。我们希望从基础设施的角度来看，在Web 3.0上工作感觉就像Web 1.0时代的美好时光，同时提供前所未有的代理、可用性、安全和隐私级别。

为了实现文件共享的根源上隐私的需求——就像它在以太坊中如此有效——Swarm在同样基本和绝对的层面上实现强制匿名。Web 2.0的经验教训告诉我们，应该谨慎地给予信任，并且只给予那些值得信任和尊重的人。数据是有毒的[Schneier, 2019]，我们必须谨慎对待数据，以便对自己和我们承担责任的人负责。稍后我们将解释Swarm如何提供完整和基本的用户隐私。

当然，为了完全过渡到一个Web 3.0的去中心化世界，我们还需要处理激励和信任的维度，传统上通过将责任移交给（通常不值得信任的）集中化守门人来“解决”这些问题。正如我们所注意到的，这也是BitTorrent努力解决的一个问题，它用过多的种子比率和私有（即集中的）跟踪器来解决这些问题。

在ZeroNet或MaidSafe等各种项目中，缺乏可靠托管和存储内容的动机问题很明显。分布式文档存储激励仍然是一个比较新的研究领域，特别是在区块链技术的背景下。Tor网络已经给出了一些建议[Jansen等人，2014年，Ghosh等人，2014]，但这些方案主要是学术性的，它们没有构建在底层网络系统的核心。比特币的技术已经被重新用于驱动其他系统，如Permacoin [Miller et al.， 2014]，一些项目已经创建了自己的区块链，如Sia [Vorick and Champine, 2014]或Filecoin [Filecoin, 2014] IPFS。BitTorrent目前正在用他们自己的代币来试水区块链激励机制[Tron Foundation, 2019, BitTorrent Foundation, 2019]。然而，即使将所有这些方法结合起来，要满足Web 3.0 Dapp开发人员的特定需求，仍然需要克服许多障碍。

稍后我们将看到Swarm如何提供全套的激励措施，以及其他的检查机制和平衡机制，以确保节点的工作有利于整个Swarm。这包括将大量磁盘空间出租给愿意付费的用户（不管其内容的受欢迎程度），同时确保有一种方法可以将你的交互式动态内容存储在云中，我们称之为上传和消失。

任何对等内容分发的激励系统的目标都是鼓励合作行为，抑制搭便车行为：对有限资源的无偿消耗。这里概述的激励策略旨在满足下列限制条件：

* 符合节点自身的利益，不管其他节点是否遵循。
* 花费其他节点的资源一定很昂贵。
* 它不会增加不合理的管理费用。
* 它很好地处理了“幼稚”节点。
* 奖励那些表现良好的人，包括那些遵循这一策略的人。

在Swarm的场景下，存储和带宽是两种最重要的有限资源，这反映在我们的激励方案中。对带宽使用的激励旨在实现快速和可靠的数据提供，而存储激励旨在确保长期的数据存储。通过这种方式，我们确保了Web应用程序开发的所有需求都得到了满足，并且激励机制是一致的，这样每个节点的行为不仅有利于自身，而且有利于整个网络。

## 2 公平数据经济

在Web 3.0时代，互联网不再仅仅是极客们的小众领域，而是成为了创造价值的基本渠道，在整体经济活动中占有巨大份额。然而，当前的数据经济非常不公，收益的分配由那些控制数据的人控制——大部分是公司将数据保存在孤立的数据竖井中。为了实现公平数据经济的目标，必须解决许多社会、法律和技术问题。我们现在将描述一些目前存在的问题，以及Swarm将如何解决这些问题。

#### 2.1 数据经济的当前状态

数字镜像世界已经存在。虚拟空间是物理空间的影子，并由大量数据组成。然而，越来越多的数据将继续与这些平行世界同步，这就需要新的基础设施和市场，并创造新的商业机会。目前只有相对粗糙的方法来衡量整体数据经济的规模，但对于美国来说，有一项数据显示，2019年数据（包括相关软件和知识产权）的金融价值为1.4万亿至2万亿美元（《经济学家，2020a》）。欧盟委员会预计，2025年欧盟27国的数据经济数据将达到8290亿欧元（2018年为3010亿欧元）[欧盟委员会，2020a]。

尽管有如此巨大的价值，现有数据经济所产生财富的不对称分配已经被成为一个主要的人道主义问题[经济学家，2020c]。随着数据所带来的效率和生产率的提高，由此产生的利润需要进行分配。如今，收益分配非常不均：公司的数据集越大，它就能从数据中学到更多东西，吸引更多用户，从而获得更多数据。目前，这一点在FAANG等占主导地位的大型科技公司中表现得最为明显，但据预测，这在非科技行业也将变得越来越重要，甚至在民族国家。因此，各公司竞相在某个特定领域占据主导地位，而托管这些平台的国家将获得优势。正如联合国贸易和发展会议（the United Nations Conference on Trade and Development, 2020c）所警告的那样，由于非洲和拉丁美洲所拥有的情报太少，它们有可能成为原始数据的出口国，然后付钱给其他国家，让它们进口所提供的情报。另一个问题是，如果一家大公司垄断了一个特定的数据市场，它也可能成为数据的唯一买家——保持对定价的完全控制，并有可能操纵提供数据的“工资”，人为压低价格。在很多方面，我们已经看到了这方面的证据。

政府正越来越多地封锁和过滤数据的流动，基于保护公民、主权和国家经济的熟悉推理[经济学家，2020亿]。几位安全专家泄露的信息表明，为了让政府适当地考虑国家安全，数据应该放在离产生地近的地方，而不是留在其他国家。GDPR就是已经建立起来的“数字边界”的一个例子——只有在适当的保护措施到位的情况下，数据才可能离开欧盟。印度、俄罗斯和中国等其他国家也对数据实施了地理限制。欧盟委员会已承诺密切监测这些国家的政策，并通过世界贸易组织的行动解决贸易谈判中对数据流动的任何限制[欧盟委员会，2020b]。

尽管人们对数据的潮起潮落越来越感兴趣，但大型科技公司仍然牢牢地掌握着其中的大部分，而且魔鬼隐藏在细节中。Swarm的隐私优先模式要求不向任何第三方泄露个人数据，一切都是端到端封装加密的，这终结了服务提供商聚合和利用巨大数据集的能力。这样做的结果是，对数据的控制仍然是分散的，并与它所属的个人有关，而不是集中在服务提供者。结果，权力也随之消失。期待负面新闻。

#### 2.2 数据主权的当前状态和问题

由于上述浮士德式交易的结果，目前的万维网模型在很多方面都有缺陷。基础设施提供的规模经济以及社交媒体的网络效应在很大程度上是不可预见的后果，平台成为了巨大的数据竖井，在这里，大量用户数据通过属于单个组织的服务器传递和保存。这种中心化模型的“副作用”让大型私营企业有机会收集、聚合和分析用户数据，将他们的数据虹吸定位在中心化的瓶颈中：云服务器，所有的东西都在这里相遇。这正是大卫·乔姆（David Chaum）在1984年所预测的，开启了《Swarm》的灵感来源——密码朋克运动。

随着社交媒体和智能手机的兴起，以计算机为媒介的交互取代以人为媒介的交互的趋势持续发展，这使得提供数据流的公司能够轻松获取越来越多关于我们个人和社交生活的信息。这些都揭露了丰厚利润的数据市场，用户的统计数据与潜在行为相关联，从而比你自己更好地了解你。这是商人的宝库。

与此同时，数据公司的商业模式也在不断发展，从出售数据中获益，而不是从最初提供的服务中获益。目前，他们的主要收入来源是将用户画像的结果卖给广告商、营销人员和其他寻求“欺骗”公众的人。这个闭环终结在：通过在相同的平台上向用户展示这样的广告，测量用户的反应，从而创造一个反馈闭环。一个全新的行业已经从这种信息洪流中成长起来，结果，一个非常复杂的系统出现了：预测、引导和影响用户分配注意力和金钱的方式；在对刺激做出反应时，公开并有意识地利用人类的弱点；经常诉诸于高度发达和精心策划的心理操纵。事实是，毫无疑问，以商业的名义进行大规模的操纵，在这种情况下，即使是最清醒的人也无法真正行使他们的选择自由，并保持他们对于内容消费或购买习惯的内在自主偏好。

业务收入来自于向微目标用户提供广告的需求，这一事实也反映在服务质量上。内容用户的需求——内容用户过去是并且应该继续是‘最终’用户——变得次于“真正的”客户：广告商的需求，这常常导致更差的用户体验和服务质量。这在社交平台上尤其痛苦，因为网络效应导致的惯性基本上构成了用户锁定。必须纠正这些错位的激励机制。换句话说，为所有用户提供相同的服务，但用户没有这种不幸的动机，因为这种结果是由中心化的数据模型造成的。

对个人数据缺乏控制会对用户的经济潜力造成严重后果。有些人歇斯底里地将这种情况称为数据奴役。但从技术上讲，这些歇斯底里的人是正确的：我们的数字孪生兄弟被公司俘虏，被公司利用，而我们却没有任何机构代理我们，使我们脱离操纵，使我们不那么知情，并获得自由。

那么，当前的系统，将数据保存在隔离的数据集中有各种缺点：

* 不平等的机会——中心化的实体加大了不平等，因为他们的系统从实际的价值创造者那里吸走了不成比例的利润。
* 缺乏容错能力——在技术基础设施方面，特别是安全性方面，它们是单点故障。
* 腐败——决策权的中心化更容易成为社会工程、政治压力和制度化腐败的目标。
* 单一攻击目标——将大量数据集中在同一安全系统下进行攻击，因为这增加了黑客的潜在回报。
* 缺乏服务连续性保证——服务连续性掌握在组织手中，仅受声誉的微弱激励。这就带来了由于破产、监管或法律行动而导致服务意外终止的风险。
* 审查——对数据访问许可的集中控制，并在大多数情况下最终导致表达自由的减少。
* 监控——流过中心化基础设施的数据提供流量分析和其他监控方法的完美访问。
* 操纵——显示层面的垄断使得数据采集者可以通过选择显示哪些数据，以什么顺序显示，什么时候显示，来操纵民意，从而质疑个人决策的主权。

#### 2.3 走向个人数据主权时代

我们相信，去中心化是一个主要的游戏规则改变者，它本身就解决了上面列出的许多问题。

我们认为，区块链技术是实现真正自主互联网的密码朋克理想的最后一块拼图。正如Eric Hughes早在1993年就在《密码朋克宣言》（Cypherpunk Manifesto, Hughes, 1993）中提出的那样，“我们必须走到一起，创建允许匿名交易的系统。” 这本书的目标之一是展示如何将去中心化共识和点对点网络技术结合起来，形成一个坚如磐石的基础架构。这个基础不仅具有弹性、容错和可伸缩；还有平等主义和经济可持续发展，以及设计良好的激励机制。由于参与者的进入壁垒较低，这些激励的适应性确保价格自动收敛于边际成本。除此之外，还有Swarm在隐私和安全领域的强大价值主张。

Swarm是一个Web 3.0的构建堆栈，它具有去中心化、内置激励和安全等属性。特别是，该平台为参与者提供数据存储、传输、访问和认证的解决方案。这些数据服务对于经济互动越来越重要。通过为所有人提供普遍访问的服务，再加上强有力的隐私保障、没有边界或外部限制，Swarm培养了全球自愿者精神，并代表了一个自主的数字社会的基础设施。

#### 2.4 人工智能与个人主权数据

人工智能（AI）有望给我们的社会带来重大变化。一方面，它被设想为无数的商业机会，而另一方面，它预计将取代许多职业和工作，而不仅仅是增强这些工作[Lee, 2018]。

当今流行的人工智能类型——机器学习(ML)——所需要的三个“元素”是：计算能力、模型和数据。今天，计算能力已经唾手可得，专门的硬件正在开发以进一步增强处理能力。十多年来，针对人工智能人才的大规模猎头活动一直在进行，各公司设法垄断了拥有提供模型和分析任务所需专业人才的工人。然而，如今人工智能和深度学习的肮脏秘密在于算法，即“智能数学”的商品化。人工智能是开源的，而不是谷歌或Palantir赚钱的东西。释放它们超能力的真正“魔术”是获得尽可能多的数据集。

组织正在做的事情是系统地收集数据。通常的做法是通过为用户提供一些实用工具（如搜索或社交媒体）的应用程序，然后存储数据以供以后使用。这与“用户”想象的情况（在没有得到他们明确同意甚至不知情的情况下）非常不同。这种对数据的垄断让跨国公司获得了前所未有的利润，只有一些软弱无力的提议让他们与那些产生数据的人分享财务收益。但可能更糟的是，他们囤积的数据无法实现其潜在的变革价值，不仅对个人，而且对整个社会。

因此，主要数据和人工智能“超级大国”正在出现，以美国和中国的政府，以及公司总部的形式。这也许不是巧合。在全世界的公民面前，一场人工智能军备竞赛正在展开，几乎所有其他国家作为“数据殖民地”都被甩在了后面[哈拉里，2020年]。有警告称，就目前的情况来看，中国和美国将不可避免地积累起作为人工智能超级大国的不可逾越的优势[李，2018]。

其实不必如此。事实上，这很可能不会发生。因为目前的情况对数十亿人来说是一笔糟糕的交易。去中心化技术和密码学是允许数据隐私的方法，同时使公平的数据经济逐渐出现，这将呈现当前中心化数据经济的所有优点，但没有缺点。随着越来越多的用户开始意识到，他们是被骗了才把自己的数据泄露出去的。全球许多消费者和科技组织都在为这种变化而努力，支持对大数据巨头的反击。Swarm将提供基础设施来促进这一自由。

自主存储可能是个人夺回对自己数据和隐私的控制权的唯一途径，作为重获数据主权的第一步，走出过滤气泡，重新融入自己的文化。Swarm代表了当今互联网的数据分布和存储的许多问题的核心解决方案。它从一开始就是为隐私而建的，有复杂的数据加密、彻底安全、防泄漏的通信。此外，它允许基于个人的条款与第三方共享选定的数据。支付和激励是Swarm的组成部分，使财务补偿作为数据粒度共享的一个核心问题。

因为正如休斯（Hughes）所写，“开放社会中的隐私需要匿名交易系统， ...。匿名交易系统不是秘密交易系统。匿名系统容许个人在需要时并且仅在需要时透露其身份。这是隐私的本质。”

使用Swarm将允许利用更完整的数据集并创建更好的服务，同时仍然可以选择通过自我验证的匿名将其贡献给全球。世界上最好的方案。

这种新的更广泛可用性的数据，例如，对于年轻的学术学生和在人工智能和大数据领域有颠覆性想法的初创公司，将将极大地促进整个领域的发展。这对科学、医疗保健、消除贫困、环境保护、防灾等都有很大贡献。但是，尽管数据在强盗大亨和流氓国家中取得了引人注目的成功，但目前这一进程陷入了僵局。有了Swarm提供的设施，一套新的选项将为公司和服务提供商开放，虽然不同，但并不逊色。随着数据的广泛去中心化，我们可以共同拥有构建最先进的AI模型所需的极其庞大且有价值的数据集。这种数据的可携性，将带来竞争，并像以前一样，为个人提供个性化服务。传统技术已经暗示了这种趋势。但竞争环境将为所有人提供平等的环境，推动2020年的创新。

#### 2.5集体信息

集体信息从互联网出现之初就开始积累，然而这个概念最近才被认可并在开源、公平数据或信息共享等各种标题下进行讨论。

集体，如维基百科（它本身就是“集体信息”的一个例子）所定义的是:

“一群共享或被至少一个共同问题或利益所激励，或为实现共同目标而共同工作的实体。”

尽管在地理位置、政治信仰、社会地位、财富、甚至一般自由和其他人口统计方面存在差异，互联网允许集体以以前无法想象的规模形成。通过在公共论坛、评论、投票、存储库、文章和投票上的联合互动，这些集体产生的数据是一种集体信息的形式——从这些互动的痕迹中产生的元数据也是这样。如今，由于这些互动大多是由运行中心化服务器的盈利性实体推动的，所有的信息最终被存储在一个商业实体拥有的数据竖井中，其中大部分集中在几家大型科技公司的手中。虽然实际的工作结果通常是公开的，但由于这些提供者的提供的元数据通常是更有价值、更强大、更危险的贡献者互动表现形式，通常被秘密持有并赚钱。

这些“平台经济”已经变得至关重要，而且在数字化社会中只会变得越来越重要。然而，我们看到，商业玩家通过他们的用户获得的信息正越来越多地被用于违背用户的最佳利益。委婉地说，这让人怀疑这些公司是否有能力承担伴随我们集体信息力量而来的道德责任。

尽管许多国家行为者试图不受限制地获取大量个人个人数据，一些国家要求像魔法钥匙一样的后门访问，但也有例外。由于人工智能有可能被滥用和存在伦理问题的使用，一些国家已经启动了人工智能使用的“伦理”倡议、法规和认证，例如德国数据伦理委员会（Data ethics Commission）或丹麦的数据伦理印章（Data ethics Seal）。

然而，即使可以让企业表现得更值得信赖（鉴于它们的重大责任，这是适当的），仅仅数据孤岛的存在就会扼杀创新。客户端-服务器架构本身的基本形状导致了这个问题，因为这种架构将中心化数据存储（在“农场”的“服务器”上）作为默认设置（见1.1.1和1.1.2）。现在，像Swarm（1.1.3）这样有效对等网络可以改变这个架构的拓扑结构，从而实现集体信息的集体所有权。

## 1.7 愿景

Swarm是一个自治社会的基础设施。

#### 3.1 价值

Self-sovereignty意味着自由。如果我们分解它，这意味着以下元值：

* 包容性——公开和未经许可的参与。
* 完整性——隐私，来源可证明。
* 激励——节点和网络的利益对齐。
* 公正性——内容和价值中立性。

这些元价值可以有助于赋能个人和集体的系统性品质：获得自主权。

包容性要求我们立志将弱势群体纳入数据经济；并降低了定义复杂数据流和构建去中心化应用程序的门槛。Swarm是一个开放参与的网络：为发布、分享和投资你的数据提供服务和无需许可的访问。

用户可以自由表达他们的“行动”意图，并有完全的权力决定他们是否想保持匿名或分享他们的互动和偏好。网络角色的完整性是必需的。

经济激励有助于确保参与者的行为与网络期望的突发行为保持一致（见3）。

公正性确保了内容的中立性，阻止了守门人。它还重申，其他三种价值观不仅是必要的，而且是充分的：它排除了将任何特定群体视为特权，或表示偏爱任何特定来源的特定内容或数据的价值观。

#### 3.2 设计原理

信息社会及其数据经济带来了一个时代，在线交易和大数据是日常生活必不可少的，因此支撑技术是关键的基础设施。因此，这一基本层基础设施必须成为未来的证明，即为连续性提供强有力的保证。

连续性是通过以下表示为系统属性的通用需求来实现的：

* 稳定——规范和软件实现是稳定的，并能适应参与者或治理（监管，审查）的变化。
* 可扩展性——该解决方案能够容纳的用户和数据比最初的多很多个数量级，而不会在大规模采用过程中导致性能或可靠性的降低。
* 安全——该解决方案能够抵抗蓄意攻击，不受社会压力和政治影响，并且能够容忍技术依赖方面的错误（如区块链、编程语言）。
* 自我维持——解决方案作为一个自治系统独立运行，不依赖人力或组织协调的集体行动或任何法人实体的业务，也不依赖专有技术、硬件或网络基础设施。

#### 3.3 目标

当我们谈论“数据流”时，其中的一个核心方面是信息如何跨模式具有可证明的完整性，见表1。这与以太坊对世界计算机的最初愿景相对应，构成了未来数据时代的免信任（即完全可信）结构：一个支持数据存储、传输和处理的全球基础设施。

| 维度 | 模型 | 项目领域 |
| ---- | ---- | -------- |
| 时间 | 内存 | 存储     |
| 空间 | 消息 | 通信     |
| 符号 | 操纵 | 处理     |

表1：Swarm的范围和在三个维度上的数据完整性。

以太坊区块链作为世界计算机的CPU，Swarm被认为是它的“硬盘”。当然，这个模型掩盖了Swarm的复杂本质，正如我们将讨论的那样，它的能力远不止简单的存储。

Swarm项目旨在实现这一愿景，并建立世界计算机的存储和通信。

#### 3.4 影响领域

在接下来的内容中，我们试图确定产品的特征范围，这些特征范围最能表达或促进上面讨论的价值。

在无需许可参与方面的包容性最好由去中心化的对等网络来保证。允许节点提供服务并从中获得报酬将为生态系统提供一个零现金入口：没有通证的新用户可以为其他节点提供服务，直到他们积累足够的通证来使用自己的服务。一个提供分布式存储而没有守门人的去中心化网络也是包容和公正的，因为它允许冒着被监管剥夺平台的风险，为的内容创造者发布内容，这样可以保护他们的言论自由权受到审查。

内置到协议的系统经济激励，效果最好。如果协议跟踪在对等交互环境下导致开销的行为：在消息中继中证明的带宽共享就是这样一种操作，当节点接收到对它们有价值的消息时，可以立即计算记账。另一方面，承诺的服务，如长期保存数据的承诺，必须在核实后才予以奖励。为了避免公地悲剧问题，应通过惩罚性措施的威慑来强制执行个人责任，即质押保险来防范违背承诺。

在保持匿名性的同时，可以很容易地证明真实性，从而实现完整性。可证明的包含性和唯一性是允许免信任数据转换的基础。

#### 3.5 未来

未来是未知的，人类面临着许多挑战。在今天的数字社会中，可以肯定的是，国家和个人都必须对自己的数据和通信保持访问和控制的权利，才能拥有数字主权并掌控自己的命运。

Swarm的愿景和目标源于去中心化技术社区及其价值观。Swarm最初的设计目标是作为世界计算机三位一体（以太坊、Whisper和Swarm）的文件存储组件。

Swarm提供了用户设备上运行的dApps所需要的响应能力，以及基于任何类型存储基础设施（从智能手机到高可用性集群）的良好存储激励。通过对带宽和存储的激励设计，连续性得到保证。

内容创造者将从他们提供的内容中获得公平补偿，而内容消费者将为此付费。通过消除目前受益于网络效应的中间商，这些网络效应的好处和溢价将传播到整个网络。

但Swarm远不止于此。每个人，每个设备都会留下数据痕迹。这些数据被收集并存储在竖井和孤岛中，数据的价值只被部分利用，并且只有利于大型企业。

Swarm将是数字化镜像世界的首选之地。个人、社会和国家将有一个云存储解决方案，这些解决方案将不再依赖于大型供应商。

个人将能够完全控制自己的数据。人们不再是数据奴隶：用自己的数据换取服务。不仅如此，人们将能够组织成数据集体或数据合作社——为了达到共同的目标，共享某些类型的数据。

各国将建立自主的Swarm云作为数据空间，以满足新兴的人工智能产业——在工业、健康、移动和其他行业。云处于对等节点之间（尽管可能在一个保护区域内），第三方将不能干涉数据和通信的流动，或者对其进行监控、审查或操纵。然而，任何拥有适当许可的一方都能够访问它，从而有望为AI和其它服务创造公平的竞争环境。

Swarm可以成为数据存储的“中心化”场所（这里说中心化似乎有些矛盾），并促进数据的可访问性、控制和价值的公平分配，最终利用数据造福个人和社会。

Swarm将在未来的社会中无处不在，在公平数据经济社会中，为个人和设备的数据消费者提供透明和安全的数据服务。 